{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from pathlib import Path\n\n\nfrom matplotlib import rcParams\nfrom matplotlib.cm import rainbow\nimport math\nimport numpy as np\nimport pandas as pd\n\n\nfrom math import sin, cos, sqrt, atan2, radians\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import  linear_model\n\nfrom collections import Counter\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n# from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\n\n#Training\nfrom sklearn.ensemble import RandomForestRegressor\nfrom pprint import pprint\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\n\n\npd.set_option(\"display.max_columns\", 100)\n\n\n","execution_count":625,"outputs":[{"output_type":"stream","text":"/kaggle/input/ml-dataset/ML data/sample_submission.csv\n/kaggle/input/ml-dataset/ML data/test.csv\n/kaggle/input/ml-dataset/ML data/train.csv\n/kaggle/input/fare-classification/meta_data.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"R = 6373.0\n\n#lable encording\ndef encoding_label(label):\n  if(label=='correct'):\n    return 1\n  else:\n    return 0\n#calculate hours\ndef calculate_hours(time):\n    hours=time.total_seconds()\n    return hours    \n#calculate distance\ndef calculate_distance(coordinates):\n\n#     print(coordinates['pick_lat'])\n#     print(type(coordinates['pick_lat']))\n    lat1 = math.radians(coordinates['pick_lat'])\n    lon1 = math.radians(coordinates['pick_lon'])\n    lat2 = math.radians(coordinates['drop_lat'])\n    lon2 = math.radians(coordinates['drop_lon'])\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = R * c\n    return distance\n\n#Finging outliers\ndef calculate_outliers(data,features):\n    out_liers=[]\n    for feature in features:\n        column_data= data[[feature]]\n#         column_data.head()\n        print(feature)\n        column_data.sort_values(by=[feature], inplace=True)\n        \n        q1, q3= np.percentile(column_data,[5,99.9])\n        iqr = q3 - q1\n#         lower_bound = q1 -(1.5 * iqr) \n        upper_bound = q3 +(1.5 * iqr) \n        print(q1)\n        print(q3)\n#         outlier_list_col = column_data[(column_data < lower_bound) | (column_data > upper_bound)].index\n        outlier_list_col = column_data[ (column_data > upper_bound)].index\n        out_liers.extend(outlier_list_col)\n    out_liers=Counter(out_liers)\n    print(out_liers)\n    out_liers = list(index for index,count in out_liers.items() if count > 2)\n    column_data.head()\n    return out_liers\n        \n\n\n","execution_count":626,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definition"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_data = pd.read_csv(\"/kaggle/input/ml-dataset/ML data/train.csv\", index_col=\"tripid\")\ntrain_data[\"label\"]=train_data[\"label\"].apply(encoding_label).values\ntest_data = pd.read_csv(\"/kaggle/input/ml-dataset/ML data/test.csv\", index_col=\"tripid\")\nsubmissionFormatData = pd.read_csv(\"/kaggle/input/ml-dataset/ML data/sample_submission.csv\", index_col=\"tripid\")\n#training_data=train_data[\"label\"]\n# index_data=test_data[\"tripid\"]\n# train_data.head()\n# Trainng_feature=train_data[]\n# trainng_feature= train_data.loc[:,[0:12]]\n\n\n# trainng_label.head()\n# test_data.head()\n# train_data.columns.values\n# train_data.dropna()\n# train_data.dropna()","execution_count":627,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_data.index))","execution_count":628,"outputs":[{"output_type":"stream","text":"17176\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=train_data[(train_data['additional_fare']< 5000)&(train_data['duration']< 339351)&(train_data['meter_waiting'] <339312)&(train_data['meter_waiting_fare']<19570)&(train_data['meter_waiting_till_pickup']<8800)&(train_data['fare']< 25097)]","execution_count":629,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_data.index))","execution_count":630,"outputs":[{"output_type":"stream","text":"16959\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Reemove NAN tuples\n# train_data.dropna(inplace=True)\n# #dropNAN columns from test list\n# NANcolumns=test_data.columns[test_data.isna().any()].tolist()\n# #remove tuples from submissionData\n# submissionFormatData.drop(NANcolumns)\n# test_data.dropna(inplace=True)","execution_count":631,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # out_liers= calculate_outliers(train_data, [\"duration\",\"meter_waiting\",\"meter_waiting_fare\",\"fare\",\"pick_lat\",\"pick_lon\",\"drop_lat\",\"drop_lon\"])\n# # out_liers= calculate_outliers(train_data, [\"additional_fare\",\"duration\",\"meter_waiting\",\"meter_waiting_fare\",\"fare\"])\n# out_liers= calculate_outliers(train_data, [\"meter_waiting_fare\"])\n# out_liers\n# train_data.drop(out_liers,inplace=True)","execution_count":632,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Preprocessing "},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature engineering\n\n\n\ntrainng_label= train_data[\"label\"]\ntrainng_feature= train_data.loc[:,\"additional_fare\":\"fare\"]\n\n\ntrainng_feature['pickup_time'] = pd.to_datetime(trainng_feature['pickup_time'],format='%m/%d/%Y %H:%M')\ntrainng_feature['drop_time'] = pd.to_datetime(trainng_feature['drop_time'],format='%m/%d/%Y %H:%M')\ntest_data['pickup_time'] = pd.to_datetime(test_data['pickup_time'],format='%m/%d/%Y %H:%M')\ntest_data['drop_time'] = pd.to_datetime(test_data['drop_time'],format='%m/%d/%Y %H:%M')\n\n\ntrainng_feature['time_difference']=trainng_feature['drop_time']-trainng_feature['pickup_time']\ntrainng_feature['time_difference']=trainng_feature['time_difference'].apply(calculate_hours).values\ntest_data['time_difference']=test_data['drop_time']-test_data['pickup_time']\ntest_data['time_difference']=test_data['time_difference'].apply(calculate_hours).values\n\n#calculate distance\n\n# trainng_feature['time_difference']=trainng_feature['time_difference'].days\n# trainng_feature['pyear']=trainng_feature['pickup_time'].dt.year \n# trainng_feature['pmonth']=trainng_feature['pickup_time'].dt.month \n# trainng_feature['pday']=trainng_feature['pickup_time'].dt.day\n# trainng_feature['pdayofweek_num']=trainng_feature['pickup_time'].dt.dayofweek \n# trainng_feature['pHour'] = trainng_feature['pickup_time'].dt.hour \n# trainng_feature['pminute'] = trainng_feature['pickup_time'].dt.minute \n\n\n\n\ntrainng_feature=trainng_feature.drop(['pickup_time','drop_time'],axis=1)\ntest_data=test_data.drop(['pickup_time','drop_time'],axis=1)\n# trainng_feature['dyear']=trainng_feature['drop_time'].dt.year \n# trainng_feature['dmonth']=trainng_feature['drop_time'].dt.month \n# trainng_feature['dday']=trainng_feature['drop_time'].dt.day\n# trainng_feature['ddayofweek_num']=trainng_feature['drop_time'].dt.dayofweek \n# trainng_feature['dHour'] = trainng_feature['drop_time'].dt.hour \n# trainng_feature['dminute'] = trainng_feature['drop_time'].dt.minute \n# test_data.isnull().sum()\n#merginh two dataframes\ntrainng_feature[\"distance\"]=trainng_feature[['pick_lat','pick_lon','drop_lat','drop_lon']].apply(calculate_distance,axis = 1)\ntest_data[\"distance\"]=test_data[['pick_lat','pick_lon','drop_lat','drop_lon']].apply(calculate_distance,axis = 1)\n# drop columns\ntrainng_feature=trainng_feature.drop(['pick_lat','pick_lon','drop_lat','drop_lon'],axis=1)\ntest_data=test_data.drop(['pick_lat','pick_lon','drop_lat','drop_lon'],axis=1)\ntrainng_feature.head()\n# trainng_feature.isnull().sum()","execution_count":633,"outputs":[{"output_type":"execute_result","execution_count":633,"data":{"text/plain":"           additional_fare  duration  meter_waiting  meter_waiting_fare  \\\ntripid                                                                    \n189123628             10.5     834.0           56.0              0.0000   \n189125358             10.5     791.0           47.0              0.0000   \n189125719             10.5    1087.0           80.0              0.0000   \n189127273             10.5     598.0          271.0             15.6638   \n189129552             10.5    3407.0          182.0              0.0000   \n\n           meter_waiting_till_pickup     fare  time_difference   distance  \ntripid                                                                     \n189123628                       64.0   270.32            840.0   5.094369  \n189125358                      134.0   197.85            780.0   3.169052  \n189125719                       61.0   301.64           1080.0   6.307375  \n189127273                       68.0    82.30            600.0   0.862217  \n189129552                      112.0  1065.02           3420.0  24.214638  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>additional_fare</th>\n      <th>duration</th>\n      <th>meter_waiting</th>\n      <th>meter_waiting_fare</th>\n      <th>meter_waiting_till_pickup</th>\n      <th>fare</th>\n      <th>time_difference</th>\n      <th>distance</th>\n    </tr>\n    <tr>\n      <th>tripid</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>189123628</th>\n      <td>10.5</td>\n      <td>834.0</td>\n      <td>56.0</td>\n      <td>0.0000</td>\n      <td>64.0</td>\n      <td>270.32</td>\n      <td>840.0</td>\n      <td>5.094369</td>\n    </tr>\n    <tr>\n      <th>189125358</th>\n      <td>10.5</td>\n      <td>791.0</td>\n      <td>47.0</td>\n      <td>0.0000</td>\n      <td>134.0</td>\n      <td>197.85</td>\n      <td>780.0</td>\n      <td>3.169052</td>\n    </tr>\n    <tr>\n      <th>189125719</th>\n      <td>10.5</td>\n      <td>1087.0</td>\n      <td>80.0</td>\n      <td>0.0000</td>\n      <td>61.0</td>\n      <td>301.64</td>\n      <td>1080.0</td>\n      <td>6.307375</td>\n    </tr>\n    <tr>\n      <th>189127273</th>\n      <td>10.5</td>\n      <td>598.0</td>\n      <td>271.0</td>\n      <td>15.6638</td>\n      <td>68.0</td>\n      <td>82.30</td>\n      <td>600.0</td>\n      <td>0.862217</td>\n    </tr>\n    <tr>\n      <th>189129552</th>\n      <td>10.5</td>\n      <td>3407.0</td>\n      <td>182.0</td>\n      <td>0.0000</td>\n      <td>112.0</td>\n      <td>1065.02</td>\n      <td>3420.0</td>\n      <td>24.214638</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Check for outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_cols = trainng_feature.columns[trainng_feature.dtypes != \"object\"].values","execution_count":634,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# numerical_cols","execution_count":635,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_preprocessing_steps = Pipeline([\n    ('standard_scaler', StandardScaler()),\n    ('simple_imputer', SimpleImputer(strategy='mean'))\n])\n\npreprocessor = ColumnTransformer(\n    transformers = [\n        (\"numeric\", numeric_preprocessing_steps, numerical_cols)\n    ],\n    remainder = \"drop\"\n)","execution_count":636,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parameter tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# rf = RandomForestRegressor(random_state = 42)\n# print('Parameters currently in use:\\n')\n# pprint(rf.get_params())","execution_count":637,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'estimator__n_estimators': n_estimators,\n               'estimator__max_features': max_features,\n               'estimator__max_depth': max_depth,\n               'estimator__min_samples_split': min_samples_split,\n               'estimator__min_samples_leaf': min_samples_leaf,\n               'estimator__bootstrap': bootstrap}\n\nparam_grid = {\n    'estimator__bootstrap': [True],\n    'estimator__max_depth': [80, 90, 100, 110],\n    'estimator__max_features': [2, 3],\n    'estimator__min_samples_leaf': [3, 4, 5],\n    'estimator__min_samples_split': [8, 10, 12],\n    'estimator__n_estimators': [100, 200, 300, 1000]\n}\n\npprint(random_grid)","execution_count":638,"outputs":[{"output_type":"stream","text":"{'estimator__bootstrap': [True, False],\n 'estimator__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n 'estimator__max_features': ['auto', 'sqrt'],\n 'estimator__min_samples_leaf': [1, 2, 4],\n 'estimator__min_samples_split': [2, 5, 10],\n 'estimator__n_estimators': [200,\n                             400,\n                             600,\n                             800,\n                             1000,\n                             1200,\n                             1400,\n                             1600,\n                             1800,\n                             2000]}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# estimator=MultiOutputClassifier(\n\n# estimator=RandomForestClassifier(     \n#          n_estimators = 1400,\n#          min_samples_split= 5,\n#          min_samples_leaf= 1,\n#          max_features = 'sqrt',\n#          max_depth = 30,\n#          bootstrap = True\n                                    \n                                    \n#     )\n# )\n\nestimator=RandomForestClassifier(     \n#          n_estimators = 1400,\n#          min_samples_split= 5,\n#          min_samples_leaf= 1,\n#          max_features = 'sqrt',\n#          max_depth = 30,\n#          bootstrap = True\n            max_depth=90,\n            max_features=3,\n            min_samples_leaf=3,\n            min_samples_split=8,\n            n_estimators=1000,\n            bootstrap=True                        \n                                    \n    )","execution_count":639,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_pipeline = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"estimator\", estimator),\n])\n# pprint(full_pipeline.get_params().keys())","execution_count":640,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(type(trainng_label))\n# Use the random grid to search for best hyperparameters\n# First create the base model to tune\n# rf = RandomForestClassifier()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\n# rf_random = RandomizedSearchCV(full_pipeline, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1,scoring ='f1')\n# Fit the random search model\n# rf_random.fit( trainng_feature, trainng_label)","execution_count":641,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grid_search = GridSearchCV(full_pipeline, param_grid = param_grid,cv = 3, n_jobs = -1, verbose = 2,scoring ='f1')\n# grid_search.fit( trainng_feature, trainng_label)","execution_count":642,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rf_random.best_params_\n# grid_search.best_estimator_","execution_count":643,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_pipeline","execution_count":644,"outputs":[{"output_type":"execute_result","execution_count":644,"data":{"text/plain":"Pipeline(memory=None,\n         steps=[('preprocessor',\n                 ColumnTransformer(n_jobs=None, remainder='drop',\n                                   sparse_threshold=0.3,\n                                   transformer_weights=None,\n                                   transformers=[('numeric',\n                                                  Pipeline(memory=None,\n                                                           steps=[('standard_scaler',\n                                                                   StandardScaler(copy=True,\n                                                                                  with_mean=True,\n                                                                                  with_std=True)),\n                                                                  ('simple_imputer',\n                                                                   SimpleImputer(add_indicator=False,\n                                                                                 copy=True,\n                                                                                 fill_value=None,\n                                                                                 missing...\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=90, max_features=3,\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=3, min_samples_split=8,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=1000, n_jobs=None,\n                                        oob_score=False, random_state=None,\n                                        verbose=0, warm_start=False))],\n         verbose=False)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Creating the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_eval, y_train, y_eval = train_test_split(\n    trainng_feature,\n    trainng_label,\n    test_size=0.33,\n    shuffle=True,\n    stratify= trainng_label,\n    random_state=6\n)\n# X_train.head()\n\ny_train.shape","execution_count":645,"outputs":[{"output_type":"execute_result","execution_count":645,"data":{"text/plain":"(11362,)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_pipeline.fit(X_train, y_train)\n\n# Predict on evaluation set\n# This competition wants probabilities, not labels\npreds = full_pipeline.predict(X_eval)\npreds\n","execution_count":646,"outputs":[{"output_type":"execute_result","execution_count":646,"data":{"text/plain":"array([1, 0, 1, ..., 1, 1, 1])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"test_probas[0].shape\", preds.shape)","execution_count":647,"outputs":[{"output_type":"stream","text":"test_probas[0].shape (5597,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds = pd.DataFrame(\n    {\n        \"prediction\": preds\n    },\n    index = y_eval.index\n)\nprint(\"y_preds.shape:\", y_preds.shape)\ny_preds.head()","execution_count":648,"outputs":[{"output_type":"stream","text":"y_preds.shape: (5597, 1)\n","name":"stdout"},{"output_type":"execute_result","execution_count":648,"data":{"text/plain":"           prediction\ntripid               \n189978643           1\n190044131           0\n200709715           1\n199929524           1\n203594678           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction</th>\n    </tr>\n    <tr>\n      <th>tripid</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>189978643</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>190044131</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>200709715</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199929524</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>203594678</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Test model"},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y_eval, y_preds, average=None)","execution_count":649,"outputs":[{"output_type":"execute_result","execution_count":649,"data":{"text/plain":"array([0.65760198, 0.97332691])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_pipeline.fit(trainng_feature, trainng_label)","execution_count":650,"outputs":[{"output_type":"execute_result","execution_count":650,"data":{"text/plain":"Pipeline(memory=None,\n         steps=[('preprocessor',\n                 ColumnTransformer(n_jobs=None, remainder='drop',\n                                   sparse_threshold=0.3,\n                                   transformer_weights=None,\n                                   transformers=[('numeric',\n                                                  Pipeline(memory=None,\n                                                           steps=[('standard_scaler',\n                                                                   StandardScaler(copy=True,\n                                                                                  with_mean=True,\n                                                                                  with_std=True)),\n                                                                  ('simple_imputer',\n                                                                   SimpleImputer(add_indicator=False,\n                                                                                 copy=True,\n                                                                                 fill_value=None,\n                                                                                 missing...\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=90, max_features=3,\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=3, min_samples_split=8,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=1000, n_jobs=None,\n                                        oob_score=False, random_state=None,\n                                        verbose=0, warm_start=False))],\n         verbose=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_probas = full_pipeline.predict(test_data)\ntest_probas","execution_count":651,"outputs":[{"output_type":"execute_result","execution_count":651,"data":{"text/plain":"array([1, 1, 1, ..., 1, 1, 1])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make sure we have the rows in the same order\nnp.testing.assert_array_equal(test_data.index.values, \n                              submissionFormatData.index.values)\n\n\nsubmissionFormatData[\"prediction\"]=test_probas\nsubmissionFormatData.head()\n\nsubmissionFormatData.to_csv('my_submission.csv', index=True)","execution_count":652,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Show output"},{"metadata":{"trusted":true},"cell_type":"code","source":"!head my_submission.csv","execution_count":653,"outputs":[{"output_type":"stream","text":"tripid,prediction\r\n213284604,1\r\n213286352,1\r\n213293973,1\r\n213294622,1\r\n213298687,1\r\n213299545,1\r\n213302332,1\r\n213302671,1\r\n213305594,1\r\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}