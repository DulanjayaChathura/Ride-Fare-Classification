{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from pathlib import Path\n\n\nfrom matplotlib import rcParams\nfrom matplotlib.cm import rainbow\nimport math\nimport numpy as np\nimport pandas as pd\n\n\nfrom math import sin, cos, sqrt, atan2, radians\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import  linear_model\n\nfrom collections import Counter\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n# from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nimport matplotlib.pyplot as plt\n\n#Training\nfrom sklearn.ensemble import RandomForestRegressor\nfrom pprint import pprint\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\n\n\npd.set_option(\"display.max_columns\", 100)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"R = 6373.0\n\n#lable encording\ndef encoding_label(label):\n  if(label=='correct'):\n    return 1\n  else:\n    return 0\n#calculate hours\ndef calculate_hours(time):\n    hours=time.total_seconds()\n    return hours    \n#calculate distance\ndef calculate_distance(coordinates):\n\n#     print(coordinates['pick_lat'])\n#     print(type(coordinates['pick_lat']))\n    lat1 = math.radians(coordinates['pick_lat'])\n    lon1 = math.radians(coordinates['pick_lon'])\n    lat2 = math.radians(coordinates['drop_lat'])\n    lon2 = math.radians(coordinates['drop_lon'])\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n    distance = R * c\n    return distance\n\n#Finging outliers\ndef calculate_outliers(data,features):\n    out_liers=[]\n    for feature in features:\n        column_data= data[[feature]]\n#         column_data.head()\n        print(feature)\n        column_data.sort_values(by=[feature], inplace=True)\n        \n        q1, q3= np.percentile(column_data,[5,99.9])\n        iqr = q3 - q1\n#         lower_bound = q1 -(1.5 * iqr) \n        upper_bound = q3 +(1.5 * iqr) \n        print(q1)\n        print(q3)\n#         outlier_list_col = column_data[(column_data < lower_bound) | (column_data > upper_bound)].index\n        outlier_list_col = column_data[ (column_data > upper_bound)].index\n        out_liers.extend(outlier_list_col)\n    out_liers=Counter(out_liers)\n    print(out_liers)\n    out_liers = list(index for index,count in out_liers.items() if count > 2)\n    column_data.head()\n    return out_liers\n        \n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definition"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_data = pd.read_csv(\"/kaggle/input/ml-dataset/ML data/train.csv\", index_col=\"tripid\")\ntrain_data[\"label\"]=train_data[\"label\"].apply(encoding_label).values\ntest_data = pd.read_csv(\"/kaggle/input/ml-dataset/ML data/test.csv\", index_col=\"tripid\")\nsubmissionFormatData = pd.read_csv(\"/kaggle/input/ml-dataset/ML data/sample_submission.csv\", index_col=\"tripid\")\n#training_data=train_data[\"label\"]\n# index_data=test_data[\"tripid\"]\n# train_data.head()\n# Trainng_feature=train_data[]\n# trainng_feature= train_data.loc[:,[0:12]]\n\n\n# trainng_label.head()\n# test_data.head()\n# train_data.columns.values\n# train_data.dropna()\n# train_data.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_data.index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=train_data[(train_data['additional_fare']< 5000)&(train_data['duration']< 339351)&(train_data['meter_waiting'] <339312)&(train_data['meter_waiting_fare']<19570)&(train_data['meter_waiting_till_pickup']<8800)&(train_data['fare']< 25097)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_cleaner=[train_data,test_data ]\nfor dataset in data_cleaner:    \n    dataset['additional_fare'].fillna(dataset['additional_fare'].median(), inplace = True)\n    dataset['duration'].fillna(dataset['duration'].median(), inplace = True)\n    dataset['meter_waiting'].fillna(dataset['meter_waiting'].median(), inplace = True)\n    dataset['meter_waiting_fare'].fillna(dataset['meter_waiting_fare'].median(), inplace = True)\n    dataset['meter_waiting_till_pickup'].fillna(dataset['meter_waiting_till_pickup'].median(), inplace = True)\n    dataset['fare'].fillna(dataset['fare'].median(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#graph distribution of quantitative data\nplt.figure(figsize=[16,12])\n\nplt.subplot(231)\nplt.boxplot(x=train_data['meter_waiting'], showmeans = True, meanline = True)\nplt.title('meter_waiting')\nplt.ylabel('meter_waiting ($)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_data.index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #Reemove NAN tuples\n# train_data.dropna(inplace=True)\n# #dropNAN columns from test list\n# NANcolumns=test_data.columns[test_data.isna().any()].tolist()\n# #remove tuples from submissionData\n# submissionFormatData.drop(NANcolumns)\n# test_data.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # out_liers= calculate_outliers(train_data, [\"duration\",\"meter_waiting\",\"meter_waiting_fare\",\"fare\",\"pick_lat\",\"pick_lon\",\"drop_lat\",\"drop_lon\"])\n# # out_liers= calculate_outliers(train_data, [\"additional_fare\",\"duration\",\"meter_waiting\",\"meter_waiting_fare\",\"fare\"])\n# out_liers= calculate_outliers(train_data, [\"meter_waiting_fare\"])\n# out_liers\n# train_data.drop(out_liers,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Preprocessing "},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature engineering\n\n\n\ntrainng_label= train_data[\"label\"]\ntrainng_feature= train_data.loc[:,\"additional_fare\":\"fare\"]\n\n\ntrainng_feature['pickup_time'] = pd.to_datetime(trainng_feature['pickup_time'],format='%m/%d/%Y %H:%M')\ntrainng_feature['drop_time'] = pd.to_datetime(trainng_feature['drop_time'],format='%m/%d/%Y %H:%M')\ntest_data['pickup_time'] = pd.to_datetime(test_data['pickup_time'],format='%m/%d/%Y %H:%M')\ntest_data['drop_time'] = pd.to_datetime(test_data['drop_time'],format='%m/%d/%Y %H:%M')\n\n\ntrainng_feature['time_difference']=trainng_feature['drop_time']-trainng_feature['pickup_time']\ntrainng_feature['time_difference']=trainng_feature['time_difference'].apply(calculate_hours).values\ntest_data['time_difference']=test_data['drop_time']-test_data['pickup_time']\ntest_data['time_difference']=test_data['time_difference'].apply(calculate_hours).values\n\n#calculate distance\n\n# trainng_feature['time_difference']=trainng_feature['time_difference'].days\n# trainng_feature['pyear']=trainng_feature['pickup_time'].dt.year \n# trainng_feature['pmonth']=trainng_feature['pickup_time'].dt.month \n# trainng_feature['pday']=trainng_feature['pickup_time'].dt.day\n# trainng_feature['pdayofweek_num']=trainng_feature['pickup_time'].dt.dayofweek \n# trainng_feature['pHour'] = trainng_feature['pickup_time'].dt.hour \n# trainng_feature['pminute'] = trainng_feature['pickup_time'].dt.minute \n\n\n\n\ntrainng_feature=trainng_feature.drop(['pickup_time','drop_time'],axis=1)\ntest_data=test_data.drop(['pickup_time','drop_time'],axis=1)\n# trainng_feature['dyear']=trainng_feature['drop_time'].dt.year \n# trainng_feature['dmonth']=trainng_feature['drop_time'].dt.month \n# trainng_feature['dday']=trainng_feature['drop_time'].dt.day\n# trainng_feature['ddayofweek_num']=trainng_feature['drop_time'].dt.dayofweek \n# trainng_feature['dHour'] = trainng_feature['drop_time'].dt.hour \n# trainng_feature['dminute'] = trainng_feature['drop_time'].dt.minute \n# test_data.isnull().sum()\n#merginh two dataframes\ntrainng_feature[\"distance\"]=trainng_feature[['pick_lat','pick_lon','drop_lat','drop_lon']].apply(calculate_distance,axis = 1)\ntest_data[\"distance\"]=test_data[['pick_lat','pick_lon','drop_lat','drop_lon']].apply(calculate_distance,axis = 1)\n# drop columns\ntrainng_feature=trainng_feature.drop(['pick_lat','pick_lon','drop_lat','drop_lon'],axis=1)\ntest_data=test_data.drop(['pick_lat','pick_lon','drop_lat','drop_lon'],axis=1)\ntrainng_feature.head()\n# trainng_feature.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_cols = trainng_feature.columns[trainng_feature.dtypes != \"object\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# numerical_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_preprocessing_steps = Pipeline([\n    ('standard_scaler', StandardScaler()),\n    ('simple_imputer', SimpleImputer(strategy='mean'))\n])\n\npreprocessor = ColumnTransformer(\n    transformers = [\n        (\"numeric\", numeric_preprocessing_steps, numerical_cols)\n    ],\n    remainder = \"drop\"\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parameter tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# rf = RandomForestRegressor(random_state = 42)\n# print('Parameters currently in use:\\n')\n# pprint(rf.get_params())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'estimator__n_estimators': n_estimators,\n               'estimator__max_features': max_features,\n               'estimator__max_depth': max_depth,\n               'estimator__min_samples_split': min_samples_split,\n               'estimator__min_samples_leaf': min_samples_leaf,\n               'estimator__bootstrap': bootstrap}\n\nparam_grid = {\n    'estimator__bootstrap': [True],\n    'estimator__max_depth': [80, 90, 100, 110],\n    'estimator__max_features': [2, 3],\n    'estimator__min_samples_leaf': [3, 4, 5],\n    'estimator__min_samples_split': [8, 10, 12],\n    'estimator__n_estimators': [100, 200, 300, 1000]\n}\n\npprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# estimator=MultiOutputClassifier(\n\n# estimator=RandomForestClassifier(     \n#          n_estimators = 1400,\n#          min_samples_split= 5,\n#          min_samples_leaf= 1,\n#          max_features = 'sqrt',\n#          max_depth = 30,\n#          bootstrap = True\n                                    \n                                    \n#     )\n# )\n\nestimator=RandomForestClassifier(     \n#          n_estimators = 1400,\n#          min_samples_split= 5,\n#          min_samples_leaf= 1,\n#          max_features = 'sqrt',\n#          max_depth = 30,\n#          bootstrap = True\n            max_depth=90,\n            max_features=3,\n            min_samples_leaf=3,\n            min_samples_split=8,\n            n_estimators=1000,\n            bootstrap=True,\n            random_state=45\n                                    \n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_pipeline = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"estimator\", estimator),\n])\npprint(full_pipeline.get_params().keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(type(trainng_label))\n# Use the random grid to search for best hyperparameters\n# First create the base model to tune\n# rf = RandomForestClassifier()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\n# rf_random = RandomizedSearchCV(full_pipeline, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1,scoring ='f1')\n# Fit the random search model\n# rf_random.fit( trainng_feature, trainng_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grid_search = GridSearchCV(full_pipeline, param_grid = param_grid,cv = 3, n_jobs = -1, verbose = 2,scoring ='f1')\n# grid_search.fit( trainng_feature, trainng_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rf_random.best_params_\n# grid_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_pipeline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_eval, y_train, y_eval = train_test_split(\n    trainng_feature,\n    trainng_label,\n    test_size=0.33,\n    shuffle=True,\n    stratify= trainng_label,\n    random_state=6\n)\n# X_train.head()\n\ny_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_pipeline.fit(X_train, y_train)\n\n# Predict on evaluation set\n# This competition wants probabilities, not labels\npreds = full_pipeline.predict(X_eval)\npreds\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"test_probas[0].shape\", preds.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds = pd.DataFrame(\n    {\n        \"prediction\": preds\n    },\n    index = y_eval.index\n)\nprint(\"y_preds.shape:\", y_preds.shape)\ny_preds.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test model"},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y_eval, y_preds, average=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_pipeline.fit(trainng_feature, trainng_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_probas = full_pipeline.predict(test_data)\ntest_probas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make sure we have the rows in the same order\nnp.testing.assert_array_equal(test_data.index.values, \n                              submissionFormatData.index.values)\n\n\nsubmissionFormatData[\"prediction\"]=test_probas\nsubmissionFormatData.head()\n\nsubmissionFormatData.to_csv('my_submission.csv', index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Show output"},{"metadata":{"trusted":true},"cell_type":"code","source":"!head my_submission.csv","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}