{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/fare-classification/meta_data.csv\n",
      "/kaggle/input/ml-dataset/ML data/sample_submission.csv\n",
      "/kaggle/input/ml-dataset/ML data/test.csv\n",
      "/kaggle/input/ml-dataset/ML data/train.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.cm import rainbow\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import  linear_model\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "def encoding_label(label):\n",
    "  if(label=='correct'):\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# !pip install -U -q PyDrive\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Authenticate and create the PyDrive client.\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_link = \"https://drive.google.com/open?id=18478S0JLw0ISKluNjkKcnRj2OcqBVCmA\"\n",
    "# test_data_link = \"https://drive.google.com/open?id=1jdpYjY0eT6Qtfny8qOD6wbTj95T-h2mx\"\n",
    "# submissionFormat_link = \"https://drive.google.com/open?id=19r1md8qztL2aYJJW5fu4Hxqhj3XLR5LQ\"\n",
    "\n",
    "# fluff, train_data_id = train_data_link .split('=')\n",
    "# fluff, test_data_id = test_data_link.split('=')\n",
    "# fluff, submissionFormat_id = submissionFormat_link.split('=')\n",
    "# print (train_data_id,test_data_id,submissionFormat_id) # Verify that you have everything after '='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189123628</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125358</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189125719</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189127273</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189128020</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label\n",
       "tripid          \n",
       "189123628      1\n",
       "189125358      1\n",
       "189125719      1\n",
       "189127273      1\n",
       "189128020      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thisDict = {\"training_set\":train_data_id,\"test_set\":test_data_id,\"submission_format\":submissionFormat_id}\n",
    "# resultDic = {}\n",
    "# for name,id in thisDict.items():\n",
    "#   print (name, id)\n",
    "#   downloaded = drive.CreateFile({'id':id}) \n",
    "#   downloaded.GetContentFile(name+'.csv')  \n",
    "#   resultDic[name] = pd.read_csv(name+'.csv', index_col=\"tripid\")\n",
    "\n",
    "# train_data = resultDic[\"training_set\"]\n",
    "# train_data[\"label\"]=train_data[\"label\"].apply(encoding_label).values\n",
    "# test_data = resultDic[\"test_set\"]\n",
    "\n",
    "train_data = pd.read_csv(\"/kaggle/input/ml-dataset/ML data/train.csv\", index_col=\"tripid\")\n",
    "train_data[\"label\"]=train_data[\"label\"].apply(encoding_label).values\n",
    "test_data = pd.read_csv(\"/kaggle/input/ml-dataset/ML data/test.csv\", index_col=\"tripid\")\n",
    "submissionFormatData = pd.read_csv(\"/kaggle/input/ml-dataset/ML data/sample_submission.csv\", index_col=\"tripid\")\n",
    "#training_data=train_data[\"label\"]\n",
    "# index_data=test_data[\"tripid\"]\n",
    "train_data.head()\n",
    "# Trainng_feature=train_data[]\n",
    "# trainng_feature= train_data.loc[:,[0:12]]\n",
    "trainng_label= train_data[[\"label\"]]\n",
    "trainng_feature= train_data.loc[:,\"additional_fare\":\"fare\"]\n",
    "# trainng_feature=trainng_feature.drop(['pickup_time','drop_time'],axis=1)\n",
    "trainng_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = trainng_feature.columns[trainng_feature.dtypes != \"object\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_preprocessing_steps = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('simple_imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"numeric\", numeric_preprocessing_steps, numerical_cols)\n",
    "    ],\n",
    "    remainder = \"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = MultiOutputClassifier(\n",
    "    estimator=RandomForestClassifier(max_depth=10, random_state=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", estimators),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('numeric',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('standard_scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean=True,\n",
       "                                                                                  with_std=True)),\n",
       "                                                                  ('simple_imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing...\n",
       "                                                                        ccp_alpha=0.0,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=10,\n",
       "                                                                        max_features='auto',\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        max_samples=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=None,\n",
       "                                                                        min_samples_leaf=1,\n",
       "                                                                        min_samples_split=2,\n",
       "                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                        n_estimators=100,\n",
       "                                                                        n_jobs=None,\n",
       "                                                                        oob_score=False,\n",
       "                                                                        random_state=0,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional_fare</th>\n",
       "      <th>duration</th>\n",
       "      <th>meter_waiting</th>\n",
       "      <th>meter_waiting_fare</th>\n",
       "      <th>meter_waiting_till_pickup</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>drop_time</th>\n",
       "      <th>pick_lat</th>\n",
       "      <th>pick_lon</th>\n",
       "      <th>drop_lat</th>\n",
       "      <th>drop_lon</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196858394</th>\n",
       "      <td>10.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>410.0</td>\n",
       "      <td>11/30/2019 20:18</td>\n",
       "      <td>11/30/2019 20:19</td>\n",
       "      <td>6.85037</td>\n",
       "      <td>79.9221</td>\n",
       "      <td>6.84474</td>\n",
       "      <td>79.9314</td>\n",
       "      <td>60.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191473740</th>\n",
       "      <td>10.5</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>215.0</td>\n",
       "      <td>11/12/2019 19:19</td>\n",
       "      <td>11/12/2019 19:51</td>\n",
       "      <td>6.99598</td>\n",
       "      <td>79.9028</td>\n",
       "      <td>6.92720</td>\n",
       "      <td>79.8443</td>\n",
       "      <td>449.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195369258</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2579.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>28.6836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11/27/2019 12:52</td>\n",
       "      <td>11/27/2019 13:35</td>\n",
       "      <td>6.86733</td>\n",
       "      <td>79.8758</td>\n",
       "      <td>6.78777</td>\n",
       "      <td>79.9002</td>\n",
       "      <td>592.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204421493</th>\n",
       "      <td>10.5</td>\n",
       "      <td>744.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>156.0</td>\n",
       "      <td>12/27/2019 10:50</td>\n",
       "      <td>12/27/2019 11:03</td>\n",
       "      <td>6.86711</td>\n",
       "      <td>79.8654</td>\n",
       "      <td>6.87280</td>\n",
       "      <td>79.8911</td>\n",
       "      <td>131.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213456300</th>\n",
       "      <td>10.5</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>228.0</td>\n",
       "      <td>1/31/2020 0:58</td>\n",
       "      <td>1/31/2020 1:13</td>\n",
       "      <td>6.84117</td>\n",
       "      <td>79.9654</td>\n",
       "      <td>6.87333</td>\n",
       "      <td>79.8876</td>\n",
       "      <td>357.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           additional_fare  duration  meter_waiting  meter_waiting_fare  \\\n",
       "tripid                                                                    \n",
       "196858394             10.5      55.0           37.0              0.0000   \n",
       "191473740             10.5    1908.0          151.0              0.0000   \n",
       "195369258             35.0    2579.0          492.0             28.6836   \n",
       "204421493             10.5     744.0           83.0              0.0000   \n",
       "213456300             10.5     910.0            1.0              0.0000   \n",
       "\n",
       "           meter_waiting_till_pickup       pickup_time         drop_time  \\\n",
       "tripid                                                                     \n",
       "196858394                      410.0  11/30/2019 20:18  11/30/2019 20:19   \n",
       "191473740                      215.0  11/12/2019 19:19  11/12/2019 19:51   \n",
       "195369258                        0.0  11/27/2019 12:52  11/27/2019 13:35   \n",
       "204421493                      156.0  12/27/2019 10:50  12/27/2019 11:03   \n",
       "213456300                      228.0    1/31/2020 0:58    1/31/2020 1:13   \n",
       "\n",
       "           pick_lat  pick_lon  drop_lat  drop_lon    fare  \n",
       "tripid                                                     \n",
       "196858394   6.85037   79.9221   6.84474   79.9314   60.50  \n",
       "191473740   6.99598   79.9028   6.92720   79.8443  449.33  \n",
       "195369258   6.86733   79.8758   6.78777   79.9002  592.52  \n",
       "204421493   6.86711   79.8654   6.87280   79.8911  131.36  \n",
       "213456300   6.84117   79.9654   6.87333   79.8876  357.19  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "    trainng_feature,\n",
    "    trainng_label,\n",
    "    test_size=0.3,\n",
    "    shuffle=True,\n",
    "    stratify= trainng_label,\n",
    "    random_state=6\n",
    ")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on evaluation set\n",
    "# This competition wants probabilities, not labels\n",
    "preds = full_pipeline.predict(X_eval)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_probas[0].shape (5153, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"test_probas[0].shape\", preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds.shape: (5153, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204424184</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205888602</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202764678</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204205375</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205876129</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           prediction\n",
       "tripid               \n",
       "204424184           1\n",
       "205888602           1\n",
       "202764678           1\n",
       "204205375           1\n",
       "205876129           1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = pd.DataFrame(\n",
    "    {\n",
    "        \"prediction\": preds[:, 0]\n",
    "    },\n",
    "    index = y_eval.index\n",
    ")\n",
    "print(\"y_preds.shape:\", y_preds.shape)\n",
    "y_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54912517, 0.96496915])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_eval, y_preds, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('numeric',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('standard_scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean=True,\n",
       "                                                                                  with_std=True)),\n",
       "                                                                  ('simple_imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing...\n",
       "                                                                        ccp_alpha=0.0,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=10,\n",
       "                                                                        max_features='auto',\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        max_samples=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=None,\n",
       "                                                                        min_samples_leaf=1,\n",
       "                                                                        min_samples_split=2,\n",
       "                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                        n_estimators=100,\n",
       "                                                                        n_jobs=None,\n",
       "                                                                        oob_score=False,\n",
       "                                                                        random_state=0,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.fit(trainng_feature, trainng_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probas = full_pipeline.predict(test_data)\n",
    "test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have the rows in the same order\n",
    "np.testing.assert_array_equal(test_data.index.values, \n",
    "                              submissionFormatData.index.values)\n",
    "\n",
    "\n",
    "submissionFormatData[\"prediction\"]=test_probas[:, 0]\n",
    "submissionFormatData.head()\n",
    "\n",
    "submissionFormatData.to_csv('my_submission.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Show output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tripid,prediction\r\n",
      "213284604,1\r\n",
      "213286352,1\r\n",
      "213293973,1\r\n",
      "213294622,1\r\n",
      "213298687,1\r\n",
      "213299545,1\r\n",
      "213302332,1\r\n",
      "213302671,1\r\n",
      "213305594,1\r\n"
     ]
    }
   ],
   "source": [
    "!head my_submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
